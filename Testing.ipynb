{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co1215/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array as A\n",
    "from matplotlib.pyplot import subplots\n",
    "from matplotlib.patches import Rectangle, Ellipse\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import flightTools as ft\n",
    "from collections import deque\n",
    "from keras.optimizers import Adam\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rocket:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Holds all the constant attributes of the rocket\n",
    "        Units for each quantity are in the square brackets\n",
    "        \"\"\"\n",
    "        self.hull_mass = 1000                       # Mass of the rocket w/o fuel [kg]\n",
    "        self.fuel_mass = 5000                       # Initial mass of the fuel only [kg]\n",
    "        self.width = 2                              # Width [m]\n",
    "        self.height = 20                            # Height [m]\n",
    "        self.impact_velocity = 5.0                  # Speed above which rocket crashes on impact [m/s]\n",
    "        self.exhaust_velocity = A([0, 200 * 9.81])  # Specific impulse of engine [s]\n",
    "        self.max_thrust = 100000                    # Maximum thust of engine [N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flight:\n",
    "\n",
    "    def __init__(self, flight_controller=None, verbose=True):\n",
    "        \"\"\"\n",
    "        Keeps track of the data and runs the simulation for a single flight\n",
    "        \"\"\"\n",
    "                \n",
    "        # Initialise the rocket\n",
    "        self.rocket = ft.Rocket()\n",
    "        \n",
    "        # Â Simulation settings\n",
    "        self.simulation_resolution = 0.1\n",
    "        self.max_runtime = 8.0\n",
    "        self.gravitational_field = A([0.0, -9.81])\n",
    "        self.verbose = verbose\n",
    "        self.sim_scale = 5 * self.rocket.height\n",
    "\n",
    "        # Initial conditions\n",
    "        # (all of these arrays will be appended to as the simulation runs)\n",
    "        self.status = A([0]).astype('int')\n",
    "        self.angle = A([0.0])\n",
    "        self.time = A([0.0])\n",
    "        self.score = A([0.0])\n",
    "        \n",
    "        # Assign a random starting position\n",
    "        self.position = A([[0.0, \n",
    "                            np.random.uniform(self.sim_scale / 2,                        \n",
    "                            self.sim_scale - self.rocket.height)]])\n",
    "\n",
    "        # Assign a random starting velocity\n",
    "        self.velocity = A([[0.0, np.random.uniform(-10.0, 10.0)]])\n",
    "        \n",
    "        self.acceleration = A([self.gravitational_field])\n",
    "        self.mass = A([self.rocket.hull_mass +\n",
    "                       self.rocket.fuel_mass])\n",
    "        self.throttle = A([0.0])\n",
    "        \n",
    "        # Check the flight controller function\n",
    "        if callable(flight_controller):\n",
    "            self.flight_controller = flight_controller\n",
    "        else:\n",
    "            self.flight_controller = ft.template_controller\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the simulation given this flight's initial conditions\n",
    "        and flight controller\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the initital state vector\n",
    "        state = A([self.position[0][1], self.velocity[0][1]])\n",
    "        \n",
    "        i, done = 1, False\n",
    "        # Start at time step 1 and run until max_runtime or the rocket lands/crashes\n",
    "        while (not done) and (self.time[i - 1] < self.max_runtime):\n",
    "\n",
    "            # Get the throttle position\n",
    "            throttle = self.flight_controller(A([state]))\n",
    "\n",
    "            # If rocket is out of fuel, cut the throttle\n",
    "            if self.mass[i - 1] <= self.rocket.hull_mass:\n",
    "                throttle = 0.0\n",
    "\n",
    "            # Update the flight based on the throttle chosen by the controller\n",
    "            state, reward, done, _ = self.update(throttle)\n",
    "      \n",
    "            # Print the current status\n",
    "            if self.verbose:\n",
    "                update_text = 'T: {:05.2f} | {:<6}'.format(self.time[i - 1] + self.simulation_resolution,\n",
    "                                                           self.status_string())\n",
    "                print('\\r', update_text, end='')\n",
    "\n",
    "            # Iterate\n",
    "            i += 1\n",
    "\n",
    "    def update(self, throttle):\n",
    "        \"\"\"\n",
    "        Updates the position, velocity and mass of the rocket at each\n",
    "        timestep, given the previous state and the current throttle setting\n",
    "        \"\"\"\n",
    "\n",
    "        # Set delta t for convenience\n",
    "        dt = self.simulation_resolution\n",
    "\n",
    "        # Mass expulsion needed to achieve the specified thrust\n",
    "        delta_m = (throttle * self.rocket.max_thrust * dt) / self.rocket.exhaust_velocity[1]\n",
    "\n",
    "        # Update the total mass\n",
    "        self.mass = np.append(self.mass, [self.mass[-1] - delta_m])\n",
    "\n",
    "        # Update the throttle\n",
    "        self.throttle = np.append(self.throttle, [throttle])\n",
    "\n",
    "        # Update the acceleration based on the mass expulsion above\n",
    "        # Note this calculation always uses the initial mass of the rocket\n",
    "        # so the engine achieves the same acceleration regardless of how much fuel is in the rocket\n",
    "        delta_v = self.rocket.exhaust_velocity * np.log((self.mass[0]  + delta_m) / (self.mass[0]))\n",
    "        total_a = (delta_v / dt) + self.gravitational_field\n",
    "        self.acceleration = np.append(self.acceleration, [total_a], axis=0)\n",
    "\n",
    "        # Update the velocity, position and time\n",
    "        self.velocity = np.append(self.velocity, [self.velocity[-1] + total_a * dt], axis=0)\n",
    "        self.position = np.append(self.position, [self.position[-1] + self.velocity[-1] * dt], axis=0)\n",
    "        self.time = np.append(self.time, [self.time[-1] + dt])\n",
    "\n",
    "        # Asssemble the state vector\n",
    "        state = A([\n",
    "            self.position[-1][1],\n",
    "            self.velocity[-1][1]\n",
    "        ])\n",
    "        \n",
    "        # Calculate the reward\n",
    "        reward = 0\n",
    "        \n",
    "        # Add points for moving closer to the surface and slowing down\n",
    "        reward = \\\n",
    "            -1.0 * (norm(flight.position[-1]) - norm(flight.position[-2])) \\\n",
    "            -1.0 * (norm(flight.velocity[-1]) - norm(flight.velocity[-2]))\n",
    "        \n",
    "        # Subtract some points for using the engine\n",
    "        reward -= throttle * 1.0\n",
    "        \n",
    "        # Check if rocket has landed safely\n",
    "        if ((self.position[-1][1] <= 0.0) and\n",
    "            (norm(self.velocity[-1]) <= self.rocket.impact_velocity)):\n",
    "\n",
    "            self.status = np.append(self.status, [1])\n",
    "            self.position[-1] = A([[self.position[-1][0], 0]])\n",
    "            self.velocity[-1] = A([[0.0, 0.0]])\n",
    "            \n",
    "            done = True\n",
    "            reward = 100\n",
    "            \n",
    "        # Check if rocket has crashed\n",
    "        elif self.position[-1][1] <= 0.0:\n",
    "            self.status = np.append(self.status, [-1])\n",
    "            self.position[-1] = A([[self.position[-1][0], 0]])\n",
    "            self.velocity[-1] = A([[0.0, 0.0]])\n",
    "            \n",
    "            done = True\n",
    "            reward = -100\n",
    "\n",
    "        # Check if rocket is out of bounds\n",
    "        elif (self.position[-1][1] + self.rocket.height) > self.sim_scale:\n",
    "            \n",
    "            self.status = np.append(self.status, [-1])\n",
    "            done = True\n",
    "            reward = -100\n",
    "            \n",
    "        # Check if rocket has gone over time\n",
    "        elif (self.time[-1] > self.max_runtime):\n",
    "            self.status = np.append(self.status, [0])\n",
    "            done = True\n",
    "            reward = -100\n",
    "            \n",
    "        else:\n",
    "            self.status = np.append(self.status, [0])\n",
    "            done = False\n",
    "            \n",
    "        self.score = np.append(self.score, reward)\n",
    "            \n",
    "        return state, reward, done, {}\n",
    "            \n",
    "    def status_string(self):\n",
    "        \"\"\"\n",
    "        Returns the current status of the rocket, given a code 0, 1 or 2\n",
    "        \"\"\"\n",
    "        j = self.status[-1]\n",
    "        if j == -1:\n",
    "            ss = 'Crashed'\n",
    "        elif j == 0:\n",
    "            ss = 'Flying'\n",
    "        else:\n",
    "            ss = 'Landed'\n",
    "        return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_predict(f, a):\n",
    "    \"\"\"\n",
    "    Returns the next state vector for a current state f given the action a\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set delta t for convenience\n",
    "    dt = f.simulation_resolution\n",
    "\n",
    "    # Mass expulsion needed to achieve the specified thrust\n",
    "    delta_m = (a * f.rocket.max_thrust * dt) / f.rocket.exhaust_velocity[1]\n",
    "\n",
    "    # Acceleration achieved\n",
    "    delta_v = f.rocket.exhaust_velocity * np.log((f.mass[0]  + delta_m) / (f.mass[0]))\n",
    "    total_a = (delta_v / dt) + f.gravitational_field\n",
    "\n",
    "    # New state\n",
    "    new_v = f.velocity[-1] + total_a * dt\n",
    "    new_x = f.position[-1] + new_v * dt\n",
    "    \n",
    "    return new_x[1], new_v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightController:\n",
    "\n",
    "    # This model represents the AI that the game will\n",
    "    # ask for moves given some data.\n",
    "\n",
    "    def __init__(self, state_size, action_size, weights=None):\n",
    "\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = 0.95    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.memory = deque(maxlen=20000)\n",
    "        self.model = self.build_model()\n",
    "        \n",
    "        \n",
    "    def build_model(self):\n",
    "        \n",
    "        # Construct the model below using\n",
    "        # model.add(...)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_shape=(self.state_size,), activation='linear'))\n",
    "        model.add(Dense(24, activation='linear'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def get_weights(self):\n",
    "\n",
    "        return self.model.get_weights()\n",
    "\n",
    "    def reset_weights(self):\n",
    "\n",
    "        shapes = [w.shape for w in self.model.get_weights()]\n",
    "\n",
    "        new_weights = []\n",
    "        for s in shapes:\n",
    "\n",
    "            new_weights.append(np.random.uniform(-1.0, 1.0, size=s))\n",
    "\n",
    "        self.model.set_weights(new_weights)\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = (reward + self.gamma *\n",
    "                          np.amax(self.model.predict(next_state)[0]))\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "    def __call__(self, state_vector):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            return np.argmax(self.model.predict(state_vector))\n",
    "        \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_size, action_size = 2, 2\n",
    "fc = FlightController(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/500, status: Flying, score: -362.71\n",
      "episode: 1/500, status: Flying, score: -364.60\n",
      "episode: 2/500, status: Flying, score: -357.20\n",
      "episode: 3/500, status: Flying, score: -361.20\n",
      "episode: 4/500, status: Flying, score: -360.79\n",
      "episode: 5/500, status: Crashed, score: -115.72\n",
      "episode: 6/500, status: Flying, score: -365.21\n",
      "episode: 7/500, status: Flying, score: -420.04\n",
      "episode: 8/500, status: Flying, score: -360.02\n",
      "episode: 9/500, status: Flying, score: -362.05\n",
      "episode: 10/500, status: Flying, score: -361.30\n",
      "episode: 11/500, status: Flying, score: -366.72\n",
      "episode: 12/500, status: Flying, score: -371.12\n",
      "episode: 13/500, status: Flying, score: -350.55\n",
      "episode: 14/500, status: Flying, score: -350.58\n",
      "episode: 15/500, status: Flying, score: -362.30\n",
      "episode: 16/500, status: Crashed, score: -101.82\n",
      "episode: 17/500, status: Flying, score: -373.59\n",
      "episode: 18/500, status: Flying, score: -358.16\n",
      "episode: 19/500, status: Flying, score: -353.39\n",
      "episode: 20/500, status: Flying, score: -373.04\n",
      "episode: 21/500, status: Flying, score: -362.15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-64e8c353e53f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-f1253df44ef8>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 target = (reward + self.gamma *\n\u001b[1;32m     55\u001b[0m                           np.amax(self.model.predict(next_state)[0]))\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mtarget_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mtarget_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1165\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2654\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m           \u001b[0mfeed_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Operation was not named: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"%s:%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1790\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_def_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "n_episodes = 500\n",
    "batch_size = 32\n",
    "\n",
    "for i in range(n_episodes):\n",
    "\n",
    "    flight = Flight(fc)\n",
    "    \n",
    "    # Get the initital state vector\n",
    "    done, total_reward = False, 0\n",
    "    state = A([[flight.position[0][1], flight.velocity[0][1]]])\n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        action = fc(state)\n",
    "        next_state, reward, done, _ = flight.update(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        \n",
    "        fc.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            print(\"episode: {}/{}, status: {}, score: {:03.2f}\".format(i, n_episodes, flight.status_string(), total_reward))\n",
    "            if i % 5 == 0:\n",
    "                # ft.FlightAnimation(flight, './training_plots/%04d.mp4' % i)\n",
    "                fc.save('./training_weights/weights_%04d_%03.2f.h5' % (i, total_reward))\n",
    "            break\n",
    "            \n",
    "        if len(fc.memory) > batch_size:\n",
    "            fc.replay(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_files = glob('./training_weights/*.h5')\n",
    "scores = A([x[:-3].split('_')[2:] for x in weight_files]).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FlightController(2, 2)\n",
    "fc.load(weight_files[np.argsort(scores[:, 1])[::-1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " T: 01.20 | Crashed"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<flightTools.FlightAnimation at 0x7f4788254a90>"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flight = Flight(fc)\n",
    "flight.run()\n",
    "ft.flight_data_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}